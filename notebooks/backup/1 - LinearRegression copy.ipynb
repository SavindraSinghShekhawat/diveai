{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning with Linear Regression (From Scratch)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from diveai.plotting import PlotBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Regularization: Mathematical Foundations\n",
    "\n",
    "This notebook explains the mathematical concepts behind our enhanced linear regression implementation supporting multiple features and regularization (Ridge, Lasso, Elastic Net).\n",
    "\n",
    "## 1. Problem Formulation\n",
    "\n",
    "**Given**:\n",
    "- Input features matrix: $X \\in \\mathbb{R}^{m \\times n}$  \n",
    "_(m samples, n features)_\n",
    "- Target vector: $y \\in \\mathbb{R}^m$  \n",
    "- Parameters: weights $w \\in \\mathbb{R}^n$, bias $b \\in \\mathbb{R}$\n",
    "\n",
    "**Goal**: Find parameters that minimize:\n",
    "$$\\min_{w,b} J(w,b) = \\text{MSE} + \\lambda R(w)$$\n",
    "\n",
    "## 2. Hypothesis Function\n",
    "\n",
    "For multiple features:\n",
    "$$\\hat{y}^{(i)} = w^T x^{(i)} + b = \\sum_{j=1}^n w_j x_j^{(i)} + b$$\n",
    "\n",
    "Matrix form:\n",
    "$$\\hat{y} = Xw + b$$\n",
    "\n",
    "## 3. Cost Function with Regularization\n",
    "\n",
    "**Base Cost (MSE)**:\n",
    "$$J_{\\text{base}} = \\frac{1}{m}\\sum_{i=1}^m (y^{(i)} - \\hat{y}^{(i)})^2$$\n",
    "\n",
    "**Regularization Terms**:\n",
    "\n",
    "| Type          | Formula                          | Code Reference                     |\n",
    "|---------------|----------------------------------|------------------------------------|\n",
    "| **L2 (Ridge)** | $\\frac{\\lambda}{2m}\\sum_{j=1}^n w_j^2$ | `lambda_/(2*m) * np.sum(weights**2)` |\n",
    "| **L1 (Lasso)** | $\\frac{\\lambda}{m}\\sum_{j=1}^n |w_j|$     | `lambda_/m * np.sum(np.abs(weights))` |\n",
    "| **Elastic Net** | $\\frac{\\lambda}{m}\\left( \\rho\\sum|w_j| + \\frac{(1-\\rho)}{2}\\sum w_j^2 \\right)$ | Combination of L1 and L2 terms |\n",
    "\n",
    "**Total Cost**:\n",
    "$$J = J_{\\text{base}} + \\text{Regularization Term}$$\n",
    "\n",
    "## 4. Gradient Descent Derivation\n",
    "\n",
    "### Base Gradients\n",
    "For parameter update:\n",
    "$$\\theta_{\\text{new}} = \\theta_{\\text{old}} - \\alpha \\frac{\\partial J}{\\partial \\theta}$$\n",
    "\n",
    "**Weight Gradient**:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial J}{\\partial w_j} &= \\frac{2}{m}\\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)})x_j^{(i)} \\\\\n",
    "&= \\frac{2}{m}X_j^T(\\hat{y} - y)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "**Bias Gradient**:\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial b} = \\frac{2}{m}\\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)})\n",
    "$$\n",
    "\n",
    "\n",
    "### Regularization Gradients\n",
    "\n",
    "| Type          | Weight Gradient Additive Term   | Code Implementation              |\n",
    "|---------------|----------------------------------|-----------------------------------|\n",
    "| **L2 (Ridge)** | $\\frac{\\lambda}{m}w$            | `(lambda_/m) * self.weights`      |\n",
    "| **L1 (Lasso)** | $\\frac{\\lambda}{m}\\text{sign}(w)$ | `(lambda_/m) * np.sign(weights)` |\n",
    "| **Elastic Net** | $\\frac{\\lambda}{m}(\\rho\\text{sign}(w) + (1-\\rho)w)$ | Combination of L1/L2 terms |\n",
    "\n",
    "## 5. Update Rules\n",
    "\n",
    "**Matrix Form Updates**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, learning_rate=0.01, iterations=1000, dive=False,\n",
    "                 regularization=None, lambda_=0.1, l1_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Enhanced Linear Regression model with regularization support\n",
    "        :param learning_rate: Step size for gradient descent\n",
    "        :param iterations: Number of gradient descent iterations\n",
    "        :param dive: Enable detailed logging of training process\n",
    "        :param regularization: Type of regularization ('l1', 'l2', 'elastic_net')\n",
    "        :param lambda_: Regularization strength\n",
    "        :param l1_ratio: Mixing parameter for Elastic Net (0-1)\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.dive = dive\n",
    "        self.regularization = regularization\n",
    "        self.lambda_ = lambda_\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train model with gradient descent and regularization\n",
    "        \"\"\"\n",
    "        m, n = X.shape  # m = samples, n = features\n",
    "        self.weights = np.zeros((n, 1))  # Proper shape for multiple features\n",
    "        self.bias = 0\n",
    "        \n",
    "        y = y.reshape(-1, 1)  # Ensure proper shape\n",
    "        \n",
    "        # Initialize logging\n",
    "        metrics = {'weights': [], 'bias': [], 'cost': []}\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            # Compute predictions and errors\n",
    "            y_pred = X @ self.weights + self.bias  # Matrix multiplication\n",
    "            error = y_pred - y\n",
    "            \n",
    "            # Compute gradients (vectorized)\n",
    "            dw = (2/m) * X.T @ error  # Correct gradient calculation\n",
    "            db = (2/m) * np.sum(error)\n",
    "            \n",
    "            # Add regularization gradients\n",
    "            if self.regularization == 'l2':\n",
    "                dw += (self.lambda_/m) * self.weights\n",
    "            elif self.regularization == 'l1':\n",
    "                dw += (self.lambda_/m) * np.sign(self.weights)\n",
    "            elif self.regularization == 'elastic_net':\n",
    "                l1_grad = self.lambda_ * self.l1_ratio * np.sign(self.weights)\n",
    "                l2_grad = self.lambda_ * (1 - self.l1_ratio) * self.weights\n",
    "                dw += (l1_grad + l2_grad)/m\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "            \n",
    "            # Compute cost with regularization\n",
    "            mse = np.mean(error**2)\n",
    "            reg_cost = self._regularization_cost(m, n)\n",
    "            total_cost = mse + reg_cost\n",
    "            \n",
    "            # Log metrics\n",
    "            metrics['weights'].append(self.weights.copy())\n",
    "            metrics['bias'].append(self.bias)\n",
    "            metrics['cost'].append(total_cost)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _regularization_cost(self, m, n):\n",
    "        \"\"\"Calculate regularization term for cost function\"\"\"\n",
    "        if not self.regularization:\n",
    "            return 0\n",
    "            \n",
    "        l1_term = np.sum(np.abs(self.weights)) \n",
    "        l2_term = np.sum(self.weights**2)\n",
    "        \n",
    "        if self.regularization == 'l1':\n",
    "            return (self.lambda_/m) * l1_term\n",
    "        elif self.regularization == 'l2':\n",
    "            return (self.lambda_/(2*m)) * l2_term\n",
    "        elif self.regularization == 'elastic_net':\n",
    "            return (self.lambda_/m) * (self.l1_ratio * l1_term + \n",
    "                                      (1 - self.l1_ratio)/2 * l2_term)\n",
    "        return 0\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Generate predictions using learned weights\"\"\"\n",
    "        return X @ self.weights + self.bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Introduction to Linear Regression**\n",
    "\n",
    "Linear regression is a fundamental algorithm in machine learning used for predicting a continuous target variable based on one or more input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mathematical Formulation**\n",
    "The linear regression model is represented as:\n",
    "$$\n",
    "\\hat{y} = w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_n\n",
    "$$\n",
    "where:\n",
    "- \\(w_0\\) is the bias (intercept),\n",
    "- \\(w_i\\) are the weights (coefficients),\n",
    "- \\(x_i\\) are the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loss Function: Mean Squared Error (MSE)**\n",
    "$$\n",
    "MSE = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "**Explanation**: MSE measures the average squared difference between predicted and actual values. It's widely used because it penalizes larger errors more heavily and is differentiable, making it suitable for optimization.\n",
    "\n",
    "**Best Practices**:\n",
    "- Use MSE when you want to penalize larger errors more heavily.\n",
    "- Be cautious with outliers as they can significantly impact MSE.\n",
    "- Consider Mean Absolute Error (MAE) if your data has many outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Linear Regression with One Independent Variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generating Synthetic Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = 2 * np.random.rand(100, 1) # One feature\n",
    "y = 4 + 3 * X + np.random.randn(100, 1) # y = 4 + 3x + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: Synthetic data allows us to understand the behavior of our algorithm in a controlled setting.\n",
    "\n",
    "**Best Practices**:\n",
    "- Use synthetic data to validate your algorithm before applying it to real-world data.\n",
    "- Ensure your synthetic data mimics the properties of real data you expect to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualize data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212cd093737d4c949f7e1ff9934272a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': 'blue', 'opacity': 1, 'size': 5},\n",
       "              'mode': 'markers',\n",
       "              'type': 'scatter',\n",
       "              'uid': '5e7002a6-9196-4cf0-82b3-88a73d0d8d4f',\n",
       "              'x': array([1.09762701, 1.43037873, 1.20552675, 1.08976637, 0.8473096 , 1.29178823,\n",
       "                          0.87517442, 1.783546  , 1.92732552, 0.76688304, 1.58345008, 1.05778984,\n",
       "                          1.13608912, 1.85119328, 0.14207212, 0.1742586 , 0.04043679, 1.66523969,\n",
       "                          1.5563135 , 1.7400243 , 1.95723668, 1.59831713, 0.92295872, 1.56105835,\n",
       "                          0.23654885, 1.27984204, 0.28670657, 1.88933783, 1.04369664, 0.82932388,\n",
       "                          0.52911122, 1.54846738, 0.91230066, 1.1368679 , 0.0375796 , 1.23527099,\n",
       "                          1.22419145, 1.23386799, 1.88749616, 1.3636406 , 0.7190158 , 0.87406391,\n",
       "                          1.39526239, 0.12045094, 1.33353343, 1.34127574, 0.42076512, 0.2578526 ,\n",
       "                          0.6308567 , 0.72742154, 1.14039354, 0.87720303, 1.97674768, 0.20408962,\n",
       "                          0.41775351, 0.32261904, 1.30621665, 0.50658321, 0.93262155, 0.48885118,\n",
       "                          0.31793917, 0.22075028, 1.31265918, 0.2763659 , 0.39316472, 0.73745034,\n",
       "                          1.64198646, 0.19420255, 1.67588981, 0.19219682, 1.95291893, 0.9373024 ,\n",
       "                          1.95352218, 1.20969104, 1.47852716, 0.07837558, 0.56561393, 0.24039312,\n",
       "                          0.5922804 , 0.23745544, 0.63596636, 0.82852599, 0.12829499, 1.38494424,\n",
       "                          1.13320291, 0.53077898, 1.04649611, 0.18788102, 1.15189299, 1.8585924 ,\n",
       "                          0.6371379 , 1.33482076, 0.26359572, 1.43265441, 0.57881219, 0.36638272,\n",
       "                          1.17302587, 0.04021509, 1.65788006, 0.00939095]),\n",
       "              'y': array([ 6.12773118,  9.19196269,  8.0822427 ,  5.73305541,  8.03018099,\n",
       "                           9.77125385,  7.80430284,  9.17071317,  8.71122394,  7.35510084,\n",
       "                           8.34717328,  8.39581459,  7.61654234, 10.53021887,  4.78258275,\n",
       "                           5.22934897,  4.13181041, 10.78158957,  8.7958526 ,  9.62206225,\n",
       "                          11.75486075,  7.44719232,  5.49839118,  9.65257177,  3.53652315,\n",
       "                           9.78314731,  4.44650074,  8.92055869,  9.05403196,  7.96848643,\n",
       "                           7.45489263,  9.55144679,  5.87567631,  9.32066865,  3.84473543,\n",
       "                           8.50826938,  8.6198263 ,  7.54659389, 10.27656784,  9.01312847,\n",
       "                           6.53347293,  5.52279093,  8.48402535,  5.68773873,  7.30603243,\n",
       "                           7.87419268,  4.82714181,  6.62282151,  6.56486486,  6.58972646,\n",
       "                           6.65126455,  7.17085827,  9.25591037,  4.64409942,  4.61741446,\n",
       "                           5.6442904 ,  8.49524077,  5.31145086,  7.19387135,  4.37349204,\n",
       "                           3.46255991,  5.10164255,  8.10465103,  5.46412914,  7.56263894,\n",
       "                           7.15683051,  8.01313715,  5.69962394,  7.71176203,  4.11500584,\n",
       "                           9.79051518,  8.52524993,  9.11581171,  6.80263458,  8.33712895,\n",
       "                           3.57164847,  6.8234777 ,  3.64124786,  4.62937253,  4.27454627,\n",
       "                           5.40986663,  8.41511002,  5.33430579,  8.24238396,  6.17417321,\n",
       "                           6.43669992,  6.13927297,  3.01887197,  8.64370877,  9.8927198 ,\n",
       "                           6.83227254,  8.32318993,  5.64761779,  7.64693763,  4.70219372,\n",
       "                           5.78074269,  6.71566794,  3.4310955 ,  8.51810767,  4.04565202])}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'Synthetic Data for Linear Regression'},\n",
       "               'xaxis': {'title': {'text': 'Feature'}},\n",
       "               'yaxis': {'title': {'text': 'Target'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pb = PlotBuilder(title=\"Synthetic Data for Linear Regression\", x_label=\"Feature\", y_label=\"Target\")\n",
    "pb.add_plot(X.flatten(), y.flatten(), plot_type='scatter')\n",
    "pb.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01 # Learning rate\n",
    "n_iters = 1000 # Number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Initialize weights and bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0 # Weight for one feature\n",
    "b = 0 # Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: 2.99983630495613, Bias: 4.186799174312735\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(X)\n",
    "mse_history = []\n",
    "for _ in range(n_iters):\n",
    "    y_predicted = w * X + b\n",
    "    mse = np.mean((y - y_predicted)**2)\n",
    "    mse_history.append(mse)\n",
    "\n",
    "    dw = -(2 / n_samples) * np.sum(X * (y - y_predicted))\n",
    "    db = -(2 / n_samples) * np.sum(y - y_predicted)\n",
    "\n",
    "    # Update weights and bias\n",
    "    w -= lr * dw\n",
    "    b -= lr * db\n",
    "\n",
    "print(f\"Weight: {w}, Bias: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: Gradient Descent is an optimization algorithm used to find the weights that minimize the loss function.\n",
    "\n",
    "**Best Practices**:\n",
    "- Choose an appropriate learning rate: too high may cause divergence, too low may result in slow convergence.\n",
    "- Monitor the loss during training to ensure the algorithm is converging.\n",
    "- Consider using adaptive learning rate methods for more complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualize MSE over iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addd1e6419e443559a8125e80e646b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'blue'},\n",
       "              'marker': {'color': 'blue', 'opacity': 1, 'size': 5},\n",
       "              'mode': 'lines',\n",
       "              'name': 'MSE',\n",
       "              'type': 'scatter',\n",
       "              'uid': '925ec216-b8e1-497b-a29a-944927d0a606',\n",
       "              'x': array([  0,   1,   2, ..., 997, 998, 999], shape=(1000,)),\n",
       "              'y': [53.330318695242276, 49.11208555114041, 45.235080729138424,\n",
       "                    ..., 0.9928051993977445, 0.9928028433141813,\n",
       "                    0.9928005023748538]}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'MSE vs. Iterations'},\n",
       "               'xaxis': {'title': {'text': 'Iterations'}},\n",
       "               'yaxis': {'title': {'text': 'Mean Squared Error'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pb = PlotBuilder(title=\"MSE vs. Iterations\", x_label=\"Iterations\", y_label=\"Mean Squared Error\")\n",
    "pb.add_plot(np.arange(n_iters), mse_history, plot_type='line', label='MSE')\n",
    "pb.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing the Best-Fit Line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b906e6c4468c4e4a89f4c90d5c5bc7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': 'blue', 'opacity': 1, 'size': 5},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Data',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'cff918b5-c4fc-43c7-8f4c-e6e9ba233c77',\n",
       "              'x': array([1.09762701, 1.43037873, 1.20552675, 1.08976637, 0.8473096 , 1.29178823,\n",
       "                          0.87517442, 1.783546  , 1.92732552, 0.76688304, 1.58345008, 1.05778984,\n",
       "                          1.13608912, 1.85119328, 0.14207212, 0.1742586 , 0.04043679, 1.66523969,\n",
       "                          1.5563135 , 1.7400243 , 1.95723668, 1.59831713, 0.92295872, 1.56105835,\n",
       "                          0.23654885, 1.27984204, 0.28670657, 1.88933783, 1.04369664, 0.82932388,\n",
       "                          0.52911122, 1.54846738, 0.91230066, 1.1368679 , 0.0375796 , 1.23527099,\n",
       "                          1.22419145, 1.23386799, 1.88749616, 1.3636406 , 0.7190158 , 0.87406391,\n",
       "                          1.39526239, 0.12045094, 1.33353343, 1.34127574, 0.42076512, 0.2578526 ,\n",
       "                          0.6308567 , 0.72742154, 1.14039354, 0.87720303, 1.97674768, 0.20408962,\n",
       "                          0.41775351, 0.32261904, 1.30621665, 0.50658321, 0.93262155, 0.48885118,\n",
       "                          0.31793917, 0.22075028, 1.31265918, 0.2763659 , 0.39316472, 0.73745034,\n",
       "                          1.64198646, 0.19420255, 1.67588981, 0.19219682, 1.95291893, 0.9373024 ,\n",
       "                          1.95352218, 1.20969104, 1.47852716, 0.07837558, 0.56561393, 0.24039312,\n",
       "                          0.5922804 , 0.23745544, 0.63596636, 0.82852599, 0.12829499, 1.38494424,\n",
       "                          1.13320291, 0.53077898, 1.04649611, 0.18788102, 1.15189299, 1.8585924 ,\n",
       "                          0.6371379 , 1.33482076, 0.26359572, 1.43265441, 0.57881219, 0.36638272,\n",
       "                          1.17302587, 0.04021509, 1.65788006, 0.00939095]),\n",
       "              'y': array([ 6.12773118,  9.19196269,  8.0822427 ,  5.73305541,  8.03018099,\n",
       "                           9.77125385,  7.80430284,  9.17071317,  8.71122394,  7.35510084,\n",
       "                           8.34717328,  8.39581459,  7.61654234, 10.53021887,  4.78258275,\n",
       "                           5.22934897,  4.13181041, 10.78158957,  8.7958526 ,  9.62206225,\n",
       "                          11.75486075,  7.44719232,  5.49839118,  9.65257177,  3.53652315,\n",
       "                           9.78314731,  4.44650074,  8.92055869,  9.05403196,  7.96848643,\n",
       "                           7.45489263,  9.55144679,  5.87567631,  9.32066865,  3.84473543,\n",
       "                           8.50826938,  8.6198263 ,  7.54659389, 10.27656784,  9.01312847,\n",
       "                           6.53347293,  5.52279093,  8.48402535,  5.68773873,  7.30603243,\n",
       "                           7.87419268,  4.82714181,  6.62282151,  6.56486486,  6.58972646,\n",
       "                           6.65126455,  7.17085827,  9.25591037,  4.64409942,  4.61741446,\n",
       "                           5.6442904 ,  8.49524077,  5.31145086,  7.19387135,  4.37349204,\n",
       "                           3.46255991,  5.10164255,  8.10465103,  5.46412914,  7.56263894,\n",
       "                           7.15683051,  8.01313715,  5.69962394,  7.71176203,  4.11500584,\n",
       "                           9.79051518,  8.52524993,  9.11581171,  6.80263458,  8.33712895,\n",
       "                           3.57164847,  6.8234777 ,  3.64124786,  4.62937253,  4.27454627,\n",
       "                           5.40986663,  8.41511002,  5.33430579,  8.24238396,  6.17417321,\n",
       "                           6.43669992,  6.13927297,  3.01887197,  8.64370877,  9.8927198 ,\n",
       "                           6.83227254,  8.32318993,  5.64761779,  7.64693763,  4.70219372,\n",
       "                           5.78074269,  6.71566794,  3.4310955 ,  8.51810767,  4.04565202])},\n",
       "             {'line': {'color': 'red'},\n",
       "              'marker': {'color': 'red', 'opacity': 1, 'size': 5},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Best Fit Line',\n",
       "              'type': 'scatter',\n",
       "              'uid': '1a7610ad-a318-4d45-ba65-82de65ebc018',\n",
       "              'x': array([1.09762701, 1.43037873, 1.20552675, 1.08976637, 0.8473096 , 1.29178823,\n",
       "                          0.87517442, 1.783546  , 1.92732552, 0.76688304, 1.58345008, 1.05778984,\n",
       "                          1.13608912, 1.85119328, 0.14207212, 0.1742586 , 0.04043679, 1.66523969,\n",
       "                          1.5563135 , 1.7400243 , 1.95723668, 1.59831713, 0.92295872, 1.56105835,\n",
       "                          0.23654885, 1.27984204, 0.28670657, 1.88933783, 1.04369664, 0.82932388,\n",
       "                          0.52911122, 1.54846738, 0.91230066, 1.1368679 , 0.0375796 , 1.23527099,\n",
       "                          1.22419145, 1.23386799, 1.88749616, 1.3636406 , 0.7190158 , 0.87406391,\n",
       "                          1.39526239, 0.12045094, 1.33353343, 1.34127574, 0.42076512, 0.2578526 ,\n",
       "                          0.6308567 , 0.72742154, 1.14039354, 0.87720303, 1.97674768, 0.20408962,\n",
       "                          0.41775351, 0.32261904, 1.30621665, 0.50658321, 0.93262155, 0.48885118,\n",
       "                          0.31793917, 0.22075028, 1.31265918, 0.2763659 , 0.39316472, 0.73745034,\n",
       "                          1.64198646, 0.19420255, 1.67588981, 0.19219682, 1.95291893, 0.9373024 ,\n",
       "                          1.95352218, 1.20969104, 1.47852716, 0.07837558, 0.56561393, 0.24039312,\n",
       "                          0.5922804 , 0.23745544, 0.63596636, 0.82852599, 0.12829499, 1.38494424,\n",
       "                          1.13320291, 0.53077898, 1.04649611, 0.18788102, 1.15189299, 1.8585924 ,\n",
       "                          0.6371379 , 1.33482076, 0.26359572, 1.43265441, 0.57881219, 0.36638272,\n",
       "                          1.17302587, 0.04021509, 1.65788006, 0.00939095]),\n",
       "              'y': array([ 7.47950052,  8.47770123,  7.80318209,  7.45591988,  6.72858927,\n",
       "                           8.06195239,  6.81217918,  9.53714522,  9.96846024,  6.48732275,\n",
       "                           8.9368902 ,  7.35999554,  7.59488057,  9.74007597,  4.61299227,\n",
       "                           4.70954645,  4.30810294,  9.18224566,  8.85548492,  9.40658723,\n",
       "                          10.05818884,  8.98148892,  6.95552426,  8.86971869,  4.89640701,\n",
       "                           8.0261158 ,  5.04687197,  9.8545034 ,  7.31771826,  6.67463506,\n",
       "                           5.77404623,  8.83194783,  6.92355183,  7.59721677,  4.29953183,\n",
       "                           7.89240995,  7.85917312,  7.88820118,  9.84897867,  8.27749775,\n",
       "                           6.34372888,  6.80884782,  8.37235795,  4.54813229,  8.18718117,\n",
       "                           8.21040683,  5.44902566,  4.96031475,  6.07926601,  6.36894472,\n",
       "                           7.60779312,  6.81826466, 10.11671862,  4.79903463,  5.43999133,\n",
       "                           5.15460347,  8.10523531,  5.70646586,  6.98451115,  5.6532727 ,\n",
       "                           5.14056463,  4.84901389,  8.12456184,  5.01585164,  5.36622899,\n",
       "                           6.39902948,  9.11248977,  4.76937504,  9.21419428,  4.76335816,\n",
       "                          10.04523628,  6.99855295, 10.04704592,  7.81567427,  8.62213862,\n",
       "                           4.4219131 ,  5.88354836,  4.90793919,  5.96354341,  4.89912662,\n",
       "                           6.09459415,  6.67224152,  4.57166315,  8.34140518,  7.5862224 ,\n",
       "                           5.77904923,  7.32611619,  4.75041148,  7.64228959,  9.76227212,\n",
       "                           6.09810859,  8.19104295,  4.9775432 ,  8.48452788,  5.92314098,\n",
       "                           5.28588737,  7.70568476,  4.30743787,  9.16016796,  4.21497049])}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'Linear Regression Fit'},\n",
       "               'xaxis': {'title': {'text': 'Feature'}},\n",
       "               'yaxis': {'title': {'text': 'Target'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = w * X + b\n",
    "\n",
    "pb = PlotBuilder(title=\"Linear Regression Fit\", x_label=\"Feature\", y_label=\"Target\")\n",
    "pb.add_plot(X.flatten(), y.flatten(), plot_type='scatter', label='Data')\n",
    "pb.add_plot(X.flatten(), y_pred.flatten(), plot_type='line', label='Best Fit Line', color='red')\n",
    "pb.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: The best-fit line represents the model's predictions across the range of input values.\n",
    "\n",
    "**Best Practices**:\n",
    "- Always visualize your data and model predictions when working with low-dimensional data.\n",
    "- Look for patterns in the residuals (differences between predictions and actual values) to identify potential issues with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Extending to Multiple Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generating Data with Multiple Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_multi = np.random.rand(100, 2) # Two features\n",
    "y_multi = 3 + 5 * X_multi[:, 0] + 2 * X_multi[:, 1] + np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a99d018fb924c3f8d6ee7bf587d9409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': 'blue', 'opacity': 1, 'size': 2.5},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Actual Data',\n",
       "              'type': 'scatter3d',\n",
       "              'uid': '4988e6e9-b288-426e-a54d-a266f8a7988d',\n",
       "              'x': array([0.37454012, 0.73199394, 0.15601864, 0.05808361, 0.60111501, 0.02058449,\n",
       "                          0.83244264, 0.18182497, 0.30424224, 0.43194502, 0.61185289, 0.29214465,\n",
       "                          0.45606998, 0.19967378, 0.59241457, 0.60754485, 0.06505159, 0.96563203,\n",
       "                          0.30461377, 0.68423303, 0.12203823, 0.03438852, 0.25877998, 0.31171108,\n",
       "                          0.54671028, 0.96958463, 0.93949894, 0.59789998, 0.0884925 , 0.04522729,\n",
       "                          0.38867729, 0.82873751, 0.28093451, 0.14092422, 0.07455064, 0.77224477,\n",
       "                          0.00552212, 0.70685734, 0.77127035, 0.35846573, 0.86310343, 0.33089802,\n",
       "                          0.31098232, 0.72960618, 0.88721274, 0.11959425, 0.76078505, 0.77096718,\n",
       "                          0.52273283, 0.02541913, 0.03142919, 0.31435598, 0.90756647, 0.41038292,\n",
       "                          0.22879817, 0.28975145, 0.92969765, 0.63340376, 0.80367208, 0.892559  ,\n",
       "                          0.80744016, 0.31800347, 0.22793516, 0.81801477, 0.00695213, 0.417411  ,\n",
       "                          0.11986537, 0.9429097 , 0.51879062, 0.3636296 , 0.96244729, 0.49724851,\n",
       "                          0.28484049, 0.60956433, 0.05147875, 0.90826589, 0.14489487, 0.98565045,\n",
       "                          0.67213555, 0.23763754, 0.36778313, 0.63352971, 0.09028977, 0.32078006,\n",
       "                          0.04077514, 0.67756436, 0.51209306, 0.64517279, 0.69093774, 0.93672999,\n",
       "                          0.34106635, 0.92469362, 0.25794163, 0.8172222 , 0.52965058, 0.09310277,\n",
       "                          0.90041806, 0.33902979, 0.72595568, 0.88708642]),\n",
       "              'y': array([0.95071431, 0.59865848, 0.15599452, 0.86617615, 0.70807258, 0.96990985,\n",
       "                          0.21233911, 0.18340451, 0.52475643, 0.29122914, 0.13949386, 0.36636184,\n",
       "                          0.78517596, 0.51423444, 0.04645041, 0.17052412, 0.94888554, 0.80839735,\n",
       "                          0.09767211, 0.44015249, 0.49517691, 0.9093204 , 0.66252228, 0.52006802,\n",
       "                          0.18485446, 0.77513282, 0.89482735, 0.92187424, 0.19598286, 0.32533033,\n",
       "                          0.27134903, 0.35675333, 0.54269608, 0.80219698, 0.98688694, 0.19871568,\n",
       "                          0.81546143, 0.72900717, 0.07404465, 0.11586906, 0.62329813, 0.06355835,\n",
       "                          0.32518332, 0.63755747, 0.47221493, 0.71324479, 0.5612772 , 0.4937956 ,\n",
       "                          0.42754102, 0.10789143, 0.63641041, 0.50857069, 0.24929223, 0.75555114,\n",
       "                          0.07697991, 0.16122129, 0.80812038, 0.87146059, 0.18657006, 0.53934224,\n",
       "                          0.8960913 , 0.11005192, 0.42710779, 0.86073058, 0.5107473 , 0.22210781,\n",
       "                          0.33761517, 0.32320293, 0.70301896, 0.97178208, 0.2517823 , 0.30087831,\n",
       "                          0.03688695, 0.50267902, 0.27864646, 0.23956189, 0.48945276, 0.24205527,\n",
       "                          0.76161962, 0.72821635, 0.63230583, 0.53577468, 0.8353025 , 0.18651851,\n",
       "                          0.59089294, 0.01658783, 0.22649578, 0.17436643, 0.38673535, 0.13752094,\n",
       "                          0.11347352, 0.87733935, 0.65998405, 0.55520081, 0.24185229, 0.89721576,\n",
       "                          0.63310146, 0.34920957, 0.89711026, 0.77987555]),\n",
       "              'z': array([ 6.09410449,  8.08954037,  4.38515472,  4.30841893,  9.28749473,\n",
       "                           5.5165751 ,  6.39558793,  4.93248746,  4.59604241,  6.52926798,\n",
       "                           7.49684777,  4.37276461,  7.81407797,  5.43961871,  6.87703383,\n",
       "                           8.27556549,  4.97764092,  8.6912187 ,  3.82889864,  6.48565984,\n",
       "                           4.52344329,  5.33173538,  5.89563528,  6.42587467,  6.1162622 ,\n",
       "                          10.85172286,  9.22249258, 10.55341753,  4.46009558,  3.01963955,\n",
       "                           4.41519201,  8.33966661,  5.26660193,  6.02301558,  5.81976472,\n",
       "                           7.1858263 ,  3.81173972,  6.47745383,  6.55792608,  5.88046556,\n",
       "                           8.77620713,  3.53586805,  5.37845918,  8.30846321,  7.49663613,\n",
       "                           5.17818591,  7.98468836,  6.69945679,  6.82653354,  3.90366301,\n",
       "                           5.51301799,  6.64272334,  6.65874746,  5.62519185,  4.81298591,\n",
       "                           5.28498579,  9.77977671, 11.76267145,  7.96239101,  9.67704512,\n",
       "                           9.78338514,  5.46151248,  4.67862215,  9.57050422,  3.28343004,\n",
       "                           5.29445203,  3.78919363,  8.44282852,  9.31464959,  4.89444698,\n",
       "                           9.00206126,  4.47528328,  4.0260445 ,  8.14213031,  3.8789667 ,\n",
       "                           6.94270843,  3.98807617,  9.09196056,  7.15355034,  5.86107901,\n",
       "                           6.14909916,  6.58759757,  7.26599793,  5.61085637,  2.36051901,\n",
       "                           6.60745178,  5.35167038,  7.42703014,  6.43563864,  7.84395539,\n",
       "                           5.43726608, 10.24390199,  4.40937982,  7.86201139,  5.65701216,\n",
       "                           4.60661612, 10.53374744,  5.79854982,  7.16311496,  9.91304516])}],\n",
       "    'layout': {'scene': {'xaxis': {'title': {'text': 'Feature 1'}},\n",
       "                         'yaxis': {'title': {'text': 'Feature 2'}},\n",
       "                         'zaxis': {'title': {'text': 'Target'}}},\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Synthetic Data with Two Features'},\n",
       "               'xaxis': {'title': {'text': 'Feature 1'}},\n",
       "               'yaxis': {'title': {'text': 'Feature 2'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pb = PlotBuilder(title=\"Synthetic Data with Two Features\", x_label='Feature 1', y_label=\"Feature 2\", z_label='Target')\n",
    "pb.add_plot(X_multi[:, 0], X_multi[:, 1], y_multi, plot_type='scatter', label='Actual Data')\n",
    "pb.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: Multiple features allow the model to capture more complex relationships in the data.\n",
    "\n",
    "**Best Practices**:\n",
    "- Ensure features are on similar scales or consider feature scaling.\n",
    "- Be cautious of multicollinearity (high correlation between features) as it can make the model unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Adding Bias to the Feature Set in Linear Regression**  \n",
    "\n",
    "**Why Add a Bias Term?** \n",
    "\n",
    "In linear regression, the model is:  \n",
    "\n",
    "$$\n",
    "\\hat{y} = w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_n\n",
    "$$  \n",
    "\n",
    "- $w_0$ (bias) allows the model to fit data that does not pass through the origin $(0,0)$.  \n",
    "- Without $w_0$, the model assumes $y = 0$ when all features are zero, which may not be correct.  \n",
    "\n",
    "**Incorporating Bias into the Feature Matrix**  \n",
    "\n",
    "To simplify computations, we rewrite:  \n",
    "\n",
    "$$\n",
    "\\hat{y} = w_0 \\cdot 1 + w_1x_1 + \\dots + w_nx_n\n",
    "$$  \n",
    "\n",
    "By adding a column of ones to $X$, we define:  \n",
    "\n",
    "$$\n",
    "X_{\\text{bias}} =\n",
    "\\begin{bmatrix}\n",
    "1 & x_{11} & x_{12} & \\dots & x_{1n} \\\\\n",
    "1 & x_{21} & x_{22} & \\dots & x_{2n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & x_{m1} & x_{m2} & \\dots & x_{mn}\n",
    "\\end{bmatrix}\n",
    "$$  \n",
    "\n",
    "Thus, we can represent the model as:  \n",
    "\n",
    "$$\n",
    "\\hat{y} = X_{\\text{bias}} \\cdot w\n",
    "$$  \n",
    "\n",
    "**Implementation in Python**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_multi_bias = np.c_[np.ones((X_multi.shape[0], 1)), X_multi] # Add bias term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementing Linear Regression for Multiple Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros(X_multi_bias.shape[1]) # [bias, w1, w2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [3.28043337 4.63890195 2.06241776]\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = X_multi_bias.shape\n",
    "mse_history_multi = []\n",
    "for _ in range(n_iters):\n",
    "    y_predicted_multi = np.dot(X_multi_bias, weights)\n",
    "    mse = np.mean((y_multi - y_predicted_multi)**2)\n",
    "    mse_history_multi.append(mse)\n",
    "\n",
    "    gradients = -(2 / n_samples) * np.dot(X_multi_bias.T, (y_multi - y_predicted_multi))\n",
    "\n",
    "    # Update weights\n",
    "    weights -= lr * gradients\n",
    "    \n",
    "print(f\"Weights: {weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d266a479568455face595d8191c2285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'blue'},\n",
       "              'marker': {'color': 'blue', 'opacity': 1, 'size': 5},\n",
       "              'mode': 'lines',\n",
       "              'name': 'MSE',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e4fb2f93-2988-4e38-95de-9c8fa4c02d42',\n",
       "              'x': array([  0,   1,   2, ..., 997, 998, 999], shape=(1000,)),\n",
       "              'y': [46.06350456787621, 43.45557629865883, 41.00123254885531, ...,\n",
       "                    1.0334420994178204, 1.0333063595439822, 1.0331709951395007]}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'MSE vs. Iterations'},\n",
       "               'xaxis': {'title': {'text': 'Iterations'}},\n",
       "               'yaxis': {'title': {'text': 'Mean Squared Error'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create MSE vs. Iterations plot\n",
    "pb = PlotBuilder(title=\"MSE vs. Iterations\", x_label=\"Iterations\", y_label=\"Mean Squared Error\")\n",
    "pb.add_plot(np.arange(n_iters), mse_history_multi, plot_type='line', label='MSE')\n",
    "pb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for a meshgrid to visualize the plane\n",
    "x1_range = np.linspace(X_multi[:, 0].min(), X_multi[:, 0].max(), 20)\n",
    "x2_range = np.linspace(X_multi[:, 1].min(), X_multi[:, 1].max(), 20)\n",
    "X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "X1_flat, X2_flat = X1.ravel(), X2.ravel()\n",
    "\n",
    "# Add bias term for prediction\n",
    "X_grid_bias = np.c_[np.ones_like(X1_flat), X1_flat, X2_flat]\n",
    "y_pred_grid = np.dot(X_grid_bias, weights).reshape(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea467f90a76a40ee8a0fc0bd7e356aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': 'blue', 'opacity': 1, 'size': 2.5},\n",
       "              'mode': 'markers',\n",
       "              'name': 'Actual Data',\n",
       "              'type': 'scatter3d',\n",
       "              'uid': '6f0e499a-5f2d-4b79-8ad2-309dd2385224',\n",
       "              'x': array([0.37454012, 0.73199394, 0.15601864, 0.05808361, 0.60111501, 0.02058449,\n",
       "                          0.83244264, 0.18182497, 0.30424224, 0.43194502, 0.61185289, 0.29214465,\n",
       "                          0.45606998, 0.19967378, 0.59241457, 0.60754485, 0.06505159, 0.96563203,\n",
       "                          0.30461377, 0.68423303, 0.12203823, 0.03438852, 0.25877998, 0.31171108,\n",
       "                          0.54671028, 0.96958463, 0.93949894, 0.59789998, 0.0884925 , 0.04522729,\n",
       "                          0.38867729, 0.82873751, 0.28093451, 0.14092422, 0.07455064, 0.77224477,\n",
       "                          0.00552212, 0.70685734, 0.77127035, 0.35846573, 0.86310343, 0.33089802,\n",
       "                          0.31098232, 0.72960618, 0.88721274, 0.11959425, 0.76078505, 0.77096718,\n",
       "                          0.52273283, 0.02541913, 0.03142919, 0.31435598, 0.90756647, 0.41038292,\n",
       "                          0.22879817, 0.28975145, 0.92969765, 0.63340376, 0.80367208, 0.892559  ,\n",
       "                          0.80744016, 0.31800347, 0.22793516, 0.81801477, 0.00695213, 0.417411  ,\n",
       "                          0.11986537, 0.9429097 , 0.51879062, 0.3636296 , 0.96244729, 0.49724851,\n",
       "                          0.28484049, 0.60956433, 0.05147875, 0.90826589, 0.14489487, 0.98565045,\n",
       "                          0.67213555, 0.23763754, 0.36778313, 0.63352971, 0.09028977, 0.32078006,\n",
       "                          0.04077514, 0.67756436, 0.51209306, 0.64517279, 0.69093774, 0.93672999,\n",
       "                          0.34106635, 0.92469362, 0.25794163, 0.8172222 , 0.52965058, 0.09310277,\n",
       "                          0.90041806, 0.33902979, 0.72595568, 0.88708642]),\n",
       "              'y': array([0.95071431, 0.59865848, 0.15599452, 0.86617615, 0.70807258, 0.96990985,\n",
       "                          0.21233911, 0.18340451, 0.52475643, 0.29122914, 0.13949386, 0.36636184,\n",
       "                          0.78517596, 0.51423444, 0.04645041, 0.17052412, 0.94888554, 0.80839735,\n",
       "                          0.09767211, 0.44015249, 0.49517691, 0.9093204 , 0.66252228, 0.52006802,\n",
       "                          0.18485446, 0.77513282, 0.89482735, 0.92187424, 0.19598286, 0.32533033,\n",
       "                          0.27134903, 0.35675333, 0.54269608, 0.80219698, 0.98688694, 0.19871568,\n",
       "                          0.81546143, 0.72900717, 0.07404465, 0.11586906, 0.62329813, 0.06355835,\n",
       "                          0.32518332, 0.63755747, 0.47221493, 0.71324479, 0.5612772 , 0.4937956 ,\n",
       "                          0.42754102, 0.10789143, 0.63641041, 0.50857069, 0.24929223, 0.75555114,\n",
       "                          0.07697991, 0.16122129, 0.80812038, 0.87146059, 0.18657006, 0.53934224,\n",
       "                          0.8960913 , 0.11005192, 0.42710779, 0.86073058, 0.5107473 , 0.22210781,\n",
       "                          0.33761517, 0.32320293, 0.70301896, 0.97178208, 0.2517823 , 0.30087831,\n",
       "                          0.03688695, 0.50267902, 0.27864646, 0.23956189, 0.48945276, 0.24205527,\n",
       "                          0.76161962, 0.72821635, 0.63230583, 0.53577468, 0.8353025 , 0.18651851,\n",
       "                          0.59089294, 0.01658783, 0.22649578, 0.17436643, 0.38673535, 0.13752094,\n",
       "                          0.11347352, 0.87733935, 0.65998405, 0.55520081, 0.24185229, 0.89721576,\n",
       "                          0.63310146, 0.34920957, 0.89711026, 0.77987555]),\n",
       "              'z': array([ 6.09410449,  8.08954037,  4.38515472,  4.30841893,  9.28749473,\n",
       "                           5.5165751 ,  6.39558793,  4.93248746,  4.59604241,  6.52926798,\n",
       "                           7.49684777,  4.37276461,  7.81407797,  5.43961871,  6.87703383,\n",
       "                           8.27556549,  4.97764092,  8.6912187 ,  3.82889864,  6.48565984,\n",
       "                           4.52344329,  5.33173538,  5.89563528,  6.42587467,  6.1162622 ,\n",
       "                          10.85172286,  9.22249258, 10.55341753,  4.46009558,  3.01963955,\n",
       "                           4.41519201,  8.33966661,  5.26660193,  6.02301558,  5.81976472,\n",
       "                           7.1858263 ,  3.81173972,  6.47745383,  6.55792608,  5.88046556,\n",
       "                           8.77620713,  3.53586805,  5.37845918,  8.30846321,  7.49663613,\n",
       "                           5.17818591,  7.98468836,  6.69945679,  6.82653354,  3.90366301,\n",
       "                           5.51301799,  6.64272334,  6.65874746,  5.62519185,  4.81298591,\n",
       "                           5.28498579,  9.77977671, 11.76267145,  7.96239101,  9.67704512,\n",
       "                           9.78338514,  5.46151248,  4.67862215,  9.57050422,  3.28343004,\n",
       "                           5.29445203,  3.78919363,  8.44282852,  9.31464959,  4.89444698,\n",
       "                           9.00206126,  4.47528328,  4.0260445 ,  8.14213031,  3.8789667 ,\n",
       "                           6.94270843,  3.98807617,  9.09196056,  7.15355034,  5.86107901,\n",
       "                           6.14909916,  6.58759757,  7.26599793,  5.61085637,  2.36051901,\n",
       "                           6.60745178,  5.35167038,  7.42703014,  6.43563864,  7.84395539,\n",
       "                           5.43726608, 10.24390199,  4.40937982,  7.86201139,  5.65701216,\n",
       "                           4.60661612, 10.53374744,  5.79854982,  7.16311496,  9.91304516])},\n",
       "             {'colorscale': [[0.0, 'rgb(255,245,240)'], [0.125,\n",
       "                             'rgb(254,224,210)'], [0.25, 'rgb(252,187,161)'],\n",
       "                             [0.375, 'rgb(252,146,114)'], [0.5, 'rgb(251,106,74)'],\n",
       "                             [0.625, 'rgb(239,59,44)'], [0.75, 'rgb(203,24,29)'],\n",
       "                             [0.875, 'rgb(165,15,21)'], [1.0, 'rgb(103,0,13)']],\n",
       "              'name': 'LR Plane',\n",
       "              'opacity': 0.5,\n",
       "              'type': 'surface',\n",
       "              'uid': '3b83714e-2f05-48a6-8092-0c1126f96430',\n",
       "              'x': array([[0.00552212, 0.05710782, 0.10869352, ..., 0.88247905, 0.93406475,\n",
       "                           0.98565045],\n",
       "                          [0.00552212, 0.05710782, 0.10869352, ..., 0.88247905, 0.93406475,\n",
       "                           0.98565045],\n",
       "                          [0.00552212, 0.05710782, 0.10869352, ..., 0.88247905, 0.93406475,\n",
       "                           0.98565045],\n",
       "                          ...,\n",
       "                          [0.00552212, 0.05710782, 0.10869352, ..., 0.88247905, 0.93406475,\n",
       "                           0.98565045],\n",
       "                          [0.00552212, 0.05710782, 0.10869352, ..., 0.88247905, 0.93406475,\n",
       "                           0.98565045],\n",
       "                          [0.00552212, 0.05710782, 0.10869352, ..., 0.88247905, 0.93406475,\n",
       "                           0.98565045]], shape=(20, 20)),\n",
       "              'y': array([[0.01658783, 0.01658783, 0.01658783, ..., 0.01658783, 0.01658783,\n",
       "                           0.01658783],\n",
       "                          [0.0676562 , 0.0676562 , 0.0676562 , ..., 0.0676562 , 0.0676562 ,\n",
       "                           0.0676562 ],\n",
       "                          [0.11872458, 0.11872458, 0.11872458, ..., 0.11872458, 0.11872458,\n",
       "                           0.11872458],\n",
       "                          ...,\n",
       "                          [0.88475019, 0.88475019, 0.88475019, ..., 0.88475019, 0.88475019,\n",
       "                           0.88475019],\n",
       "                          [0.93581856, 0.93581856, 0.93581856, ..., 0.93581856, 0.93581856,\n",
       "                           0.93581856],\n",
       "                          [0.98688694, 0.98688694, 0.98688694, ..., 0.98688694, 0.98688694,\n",
       "                           0.98688694]], shape=(20, 20)),\n",
       "              'z': array([[3.34026096, 3.57956198, 3.81886299, ..., 7.40837819, 7.64767921,\n",
       "                           7.88698022],\n",
       "                          [3.44558528, 3.6848863 , 3.92418731, ..., 7.51370251, 7.75300353,\n",
       "                           7.99230454],\n",
       "                          [3.55090961, 3.79021062, 4.02951163, ..., 7.61902683, 7.85832785,\n",
       "                           8.09762886],\n",
       "                          ...,\n",
       "                          [5.13077443, 5.37007544, 5.60937646, ..., 9.19889166, 9.43819267,\n",
       "                           9.67749369],\n",
       "                          [5.23609875, 5.47539977, 5.71470078, ..., 9.30421598, 9.54351699,\n",
       "                           9.78281801],\n",
       "                          [5.34142307, 5.58072409, 5.8200251 , ..., 9.4095403 , 9.64884132,\n",
       "                           9.88814233]], shape=(20, 20))}],\n",
       "    'layout': {'scene': {'xaxis': {'title': {'text': 'Feature 1'}},\n",
       "                         'yaxis': {'title': {'text': 'Feature 2'}},\n",
       "                         'zaxis': {'title': {'text': 'Target'}}},\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Multivariate Linear Regression Trend'},\n",
       "               'xaxis': {'title': {'text': 'Feature 1'}},\n",
       "               'yaxis': {'title': {'text': 'Feature 2'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pb = PlotBuilder(title=\"Multivariate Linear Regression Trend\", x_label='Feature 1', y_label=\"Feature 2\", z_label='Target')\n",
    "pb.add_plot(X_multi[:, 0], X_multi[:, 1], y_multi, plot_type='scatter', label='Actual Data')\n",
    "pb.add_plot(X1, X2, y_pred_grid, plot_type='surface', color='red', opacity=0.5, colorscale=\"Reds\", label='LR Plane')\n",
    "pb.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: The principle remains the same as with one feature, but now we're optimizing multiple weights simultaneously.\n",
    "\n",
    "**Best Practices**:\n",
    "- Use vectorized operations for efficiency when working with multiple features.\n",
    "- Consider feature selection techniques if you have a large number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Regularization Techniques**\n",
    "\n",
    "Regularization helps prevent overfitting by adding a penalty term to the loss function.\n",
    "\n",
    "##### **a. Ridge Regression (L2 Regularization)**\n",
    "[Code for Ridge Regression]\n",
    "\n",
    "**Explanation**: Ridge regression adds the sum of squared weights to the loss function, encouraging smaller weights.\n",
    "\n",
    "**Best Practices**:\n",
    "- Use Ridge when you suspect many features are relevant.\n",
    "- It's particularly useful when you have multicollinearity in your features.\n",
    "- Experiment with different alpha values to find the optimal balance between bias and variance.\n",
    "\n",
    "##### **b. Lasso Regression (L1 Regularization)**\n",
    "[Code for Lasso Regression]\n",
    "\n",
    "**Explanation**: Lasso adds the sum of absolute weights to the loss function, which can lead to sparse models (some weights become exactly zero).\n",
    "\n",
    "**Best Practices**:\n",
    "- Use Lasso when you believe only a few features are relevant.\n",
    "- It's great for feature selection as it can completely eliminate irrelevant features.\n",
    "- Like Ridge, try different alpha values to optimize performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Model Evaluation Metrics**\n",
    "\n",
    "##### **Calculating Mean Squared Error and R-squared**\n",
    "[Code for calculating MSE and R-squared]\n",
    "\n",
    "**Explanation**:\n",
    "- MSE: Measures the average squared difference between predictions and actual values.\n",
    "- R-squared: Represents the proportion of variance in the dependent variable that is predictable from the independent variable(s).\n",
    "\n",
    "**Best Practices**:\n",
    "- Use MSE to get an idea of the magnitude of your errors in the original unit of the target variable.\n",
    "- R-squared is useful for comparing models, but be cautious of overfitting when R-squared is very close to 1.\n",
    "- Always use a separate test set or cross-validation to get a true measure of model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Using scikit-learn for Models with Three or More Features**\n",
    "\n",
    "[Code for using scikit-learn models]\n",
    "\n",
    "**Explanation**: Scikit-learn provides efficient, well-tested implementations of various machine learning algorithms.\n",
    "\n",
    "**Best Practices**:\n",
    "- Use scikit-learn for production code and when working with larger datasets.\n",
    "- Take advantage of scikit-learn's consistent API across different models for easy experimentation.\n",
    "- Use scikit-learn's built-in cross-validation and model selection tools for robust evaluation and tuning.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Summary and Insights**\n",
    "\n",
    "This notebook demonstrates the fundamental concepts of linear regression, from basic implementation to more advanced techniques like regularization.\n",
    "\n",
    "**Key Takeaways**:\n",
    "1. Linear regression is a powerful tool for understanding relationships between variables.\n",
    "2. Regularization techniques like Ridge and Lasso can help prevent overfitting and improve model generalization.\n",
    "3. Visualizations are crucial for understanding data, model behavior, and results.\n",
    "4. While implementing algorithms from scratch is educational, using established libraries like scikit-learn is recommended for real-world applications.\n",
    "\n",
    "**Best Practices for Linear Regression**:\n",
    "- Always start with exploratory data analysis to understand your data.\n",
    "- Use simple models as a baseline before moving to more complex ones.\n",
    "- Regularly check model assumptions (linearity, independence, homoscedasticity, normality of residuals).\n",
    "- Be mindful of outliers and their impact on your model.\n",
    "- Use cross-validation for more reliable performance estimates, especially with smaller datasets.\n",
    "- Consider feature engineering to capture non-linear relationships if simple linear models aren't sufficient.\n",
    "\n",
    "\n",
    "This revised notebook now includes explanations and best practices for each major concept, providing a more comprehensive understanding of linear regression and its applications. The added context will help learners not just implement the techniques, but also understand when and why to use them in real-world scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diveai",
   "language": "python",
   "name": "diveai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
